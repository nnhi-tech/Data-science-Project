{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3xETVBDWLUm"
      },
      "source": [
        "# Sequence Analysis with Python\n",
        "\n",
        "Contact: Veli Mäkinen veli.makinen@helsinki.fi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jq4W2e1hWLUp"
      },
      "source": [
        "The following assignments introduce applications of hashing with ```dict()``` primitive of Python. While doing so, a rudimentary introduction to biological sequences is given.\n",
        "This framework is then enhanced with probabilities, leading to routines to generate random sequences under some constraints, including a general concept of *Markov-chains*. All these components illustrate the usage of ```dict()```, but at the same time introduce some other computational routines to efficiently deal with probabilities.   \n",
        "The function ```collections.defaultdict``` can be useful.\n",
        "\n",
        "Below are some \"suggested\" imports. Feel free to use and modify these, or not. Generally it's good practice to keep most or all imports in one place. Typically very close to the start of notebooks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-07-08T22:04:22.831112Z",
          "start_time": "2019-07-08T22:04:22.688031Z"
        },
        "id": "wCxPRWDzWLUq"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "from itertools import product\n",
        "\n",
        "import random\n",
        "from numpy.random import choice\n",
        "\n",
        "import requests\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zypYzSxrWLUr"
      },
      "source": [
        "The automated TMC tests do not test cell outputs. These are intended to be evaluated in the peer reviews. So it is still be a good idea to make the outputs as clear and informative as possible.\n",
        "\n",
        "To keep TMC tests running as well as possible it is recommended to keep global variable assignments in the notebook to a minimum to avoid potential name clashes and confusion. Additionally you should keep all actual code exection in main guards to keep the test running smoothly. If you run [check_sequence.py](https://raw.githubusercontent.com/saskeli/data-analysis-with-python-summer-2019/master/check_outputs.py) in the `part07-e01_sequence_analysis` folder, the script should finish very quickly and optimally produce no output.\n",
        "\n",
        "If you download data from the internet during execution (codon usage table), the parts where downloading is done should not work if you decide to submit to the tmc server. Local tests should work fine."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7IZQGS3oWLUs"
      },
      "source": [
        "## DNA and RNA\n",
        "\n",
        "A DNA molecule consist, in principle, of a chain of smaller molecules. These smaller molecules have some common basic components (bases) that repeat. For our purposes it is sufficient to know that these bases are nucleotides adenine, cytosine, guanine, and thymine with abbreviations ```A```, ```C```, ```G```, and ```T```. Given a *DNA sequence* e.g. ```ACGATGAGGCTCAT```, one can reverse engineer (with negligible loss of information) the corresponding DNA molecule.\n",
        "\n",
        "Parts of a DNA molecule can *transcribe* into an RNA molecule. In this process, thymine gets replaced by uracil (```U```).\n",
        "\n",
        "\n",
        "1. Write a function ```dna_to_rna``` to convert a given DNA sequence $s$ into an RNA sequence. For the sake of exercise, use ```dict()``` to store the symbol to symbol encoding rules. Create a program to test your function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-07-08T22:04:22.841952Z",
          "start_time": "2019-07-08T22:04:22.834721Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcTjZuopWLUt",
        "outputId": "fbf035db-cd12-444a-b449-77a3e5e6c601"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AACGUGAUUUC\n"
          ]
        }
      ],
      "source": [
        "def dna_to_rna(s):\n",
        "    '''Transcribe a DNA string into an RNA string'''\n",
        "    return s.replace('T', 'U')\n",
        "    \n",
        "if __name__ == '__main__':\n",
        "    print(dna_to_rna('AACGTGATTTC'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1v6-VFqWLUt"
      },
      "source": [
        "### Idea of solution\n",
        "\n",
        "To convert a DNA sequence into its corresponding RNA sequence, thymine (T) is substituted with uracil (U) using the Python method `replace()`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQ15iAfdWLUu"
      },
      "source": [
        "### Discussion\n",
        "\n",
        "The solution performs precisely as expeted. In molecular biology, RNA is produced from DNA through a process known as transcription. This transformation is crucial for protein synthesis, as RNA acts as the template that translates genetic instructions into proteins, which are composed of their fundamental units, amino acids."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tN-HFR9NWLUv"
      },
      "source": [
        "## Proteins\n",
        "\n",
        "Like DNA and RNA, protein molecule can be interpreted as a chain of smaller molecules, where the bases are now amino acids. RNA molecule may *translate* into a protein molecule, but instead of base by base, three bases of RNA correspond to one base of protein. That is, RNA sequence is read triplet (called codon) at a time.\n",
        "\n",
        "2. Consider the codon to amino acid conversion table in http://htmlpreview.github.io/?https://github.com/csmastersUH/data_analysis_with_python_2020/blob/master/Codon%20usage%20table.html. Write a function ```get_dict``` to read the table into a ```dict()```, such that for each RNA sequence of length 3, say $\\texttt{AGU}$, the hash table stores the conversion rule to the corresponding amino acid. You may store the html page to your local src directory,\n",
        "and parse that file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-07-08T22:04:22.867855Z",
          "start_time": "2019-07-08T22:04:22.845885Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qy48N00NWLUx",
        "outputId": "30087e63-a2f4-43ee-f99e-4b2beea86e11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'UUU': 'F', 'UCU': 'S', 'UAU': 'Y', 'UGU': 'C', 'UUC': 'F', 'UCC': 'S', 'UAC': 'Y', 'UGC': 'C', 'UUA': 'L', 'UCA': 'S', 'UAA': '*', 'UGA': '*', 'UUG': 'L', 'UCG': 'S', 'UAG': '*', 'UGG': 'W', 'CUU': 'L', 'CCU': 'P', 'CAU': 'H', 'CGU': 'R', 'CUC': 'L', 'CCC': 'P', 'CAC': 'H', 'CGC': 'R', 'CUA': 'L', 'CCA': 'P', 'CAA': 'Q', 'CGA': 'R', 'CUG': 'L', 'CCG': 'P', 'CAG': 'Q', 'CGG': 'R', 'AUU': 'I', 'ACU': 'T', 'AAU': 'N', 'AGU': 'S', 'AUC': 'I', 'ACC': 'T', 'AAC': 'N', 'AGC': 'S', 'AUA': 'I', 'ACA': 'T', 'AAA': 'K', 'AGA': 'R', 'AUG': 'M', 'ACG': 'T', 'AAG': 'K', 'AGG': 'R', 'GUU': 'V', 'GCU': 'A', 'GAU': 'D', 'GGU': 'G', 'GUC': 'V', 'GCC': 'A', 'GAC': 'D', 'GGC': 'G', 'GUA': 'V', 'GCA': 'A', 'GAA': 'E', 'GGA': 'G', 'GUG': 'V', 'GCG': 'A', 'GAG': 'E', 'GGG': 'G'}\n"
          ]
        }
      ],
      "source": [
        "def get_table():\n",
        "    ''' Fetch \"Codon Usage Table\" either from file or URL '''\n",
        "    try:\n",
        "        with open('src/codon_usage_table.html', 'r') as file:\n",
        "            html_content = file.read()\n",
        "    except:\n",
        "        url = 'https://raw.githubusercontent.com/csmastersUH/data_analysis_with_python_2020/master/Codon%20usage%20table.html'\n",
        "        response = requests.get(url)\n",
        "        html_content = response.text\n",
        "    return html_content\n",
        "\n",
        "def get_dict():\n",
        "    '''\n",
        "    Parse Codon Usage Table into Codon to Aminoacid table.\n",
        "    '''\n",
        "    html_content = get_table()\n",
        "    # Find the <pre> tag content\n",
        "    pre_content = re.search(r'<pre>(.*?)</pre>', html_content, re.DOTALL)\n",
        "    if pre_content:\n",
        "        codon_dict = {}\n",
        "        # Find all codon lines in <pre> tag to capture the codon and its corresponding amino acid\n",
        "        pattern = r'([AUGC]{3})\\s([A-Z*])'\n",
        "        matches = re.findall(pattern, html_content)\n",
        "        for codon, amino_acid in matches:\n",
        "            codon_dict[codon] = amino_acid\n",
        "        return codon_dict\n",
        "    return {}\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    codon_to_aa = get_dict()\n",
        "    print(codon_to_aa)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlRZUD8uWLUx"
      },
      "source": [
        "### Idea of solution\n",
        "\n",
        "The `get_table()` function tries to retrieve the `Codon Usage Table` from a local file. If it is fail, the function will fetche the table from the given URL. Since the retrieved data is in HTML format, the `get_table()` function is utilized to generate a dictionary that maps each codon to its corresponding amino acid."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSSa1lDtWLUy"
      },
      "source": [
        "### Discussion\n",
        "\n",
        "The output works as expected, extracting the relevant data from the Codon Usage Table. This table illustrates the frequency with which specific codons are utilized in the coding sequences of genes across various organisms. Additionally, the mapping of codons to amino acids is fundamental in molecular biology, as it enables researchers to interpret genetic sequences and predict the resulting protein structure.\n",
        "\n",
        "**Note 1:** This notebook will focus exclusively on the provided Codon Usage Table, although various such tables can be retrieved from the Internet (e.g. https://www.bioinformatics.org/sms2/codon_usage.html)\n",
        "\n",
        "**Note 2:** While a Pandas DataFrame could be a good prospective data structure, utilizing dictionaries will be sufficient."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnH7qa9-WLUy"
      },
      "source": [
        "3. Use the same conversion table as above, but now write function `get_dict_list` to read the table into a `dict()`, such that for each amino acid the hash table stores the list of codons encoding it.    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-07-08T22:04:22.882386Z",
          "start_time": "2019-07-08T22:04:22.872449Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZUbk4PwWLUz",
        "outputId": "026e9926-0f04-4166-b470-e5a3d453fc5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'F': ['UUU', 'UUC'], 'S': ['UCU', 'UCC', 'UCA', 'UCG', 'AGU', 'AGC'], 'Y': ['UAU', 'UAC'], 'C': ['UGU', 'UGC'], 'L': ['UUA', 'UUG', 'CUU', 'CUC', 'CUA', 'CUG'], '*': ['UAA', 'UGA', 'UAG'], 'W': ['UGG'], 'P': ['CCU', 'CCC', 'CCA', 'CCG'], 'H': ['CAU', 'CAC'], 'R': ['CGU', 'CGC', 'CGA', 'CGG', 'AGA', 'AGG'], 'Q': ['CAA', 'CAG'], 'I': ['AUU', 'AUC', 'AUA'], 'T': ['ACU', 'ACC', 'ACA', 'ACG'], 'N': ['AAU', 'AAC'], 'K': ['AAA', 'AAG'], 'M': ['AUG'], 'V': ['GUU', 'GUC', 'GUA', 'GUG'], 'A': ['GCU', 'GCC', 'GCA', 'GCG'], 'D': ['GAU', 'GAC'], 'G': ['GGU', 'GGC', 'GGA', 'GGG'], 'E': ['GAA', 'GAG']}\n"
          ]
        }
      ],
      "source": [
        "def get_dict_list():\n",
        "    '''\n",
        "    Map each amino acid to a list of corresponding codons.\n",
        "    {'*': ['UAA', 'UGA', 'UAG'], 'A': ['GCU', 'GCC', 'GCA', 'GCG'], ...}\n",
        "    '''\n",
        "    codon_to_aa = get_dict()\n",
        "    # Create lists for new keys\n",
        "    aa_to_codon = defaultdict(list)\n",
        "    [aa_to_codon[amino_acid].append(codon) for codon, amino_acid in codon_to_aa.items()]\n",
        "    # Convert defaultdict back to a regular dict\n",
        "    return dict(aa_to_codon)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    aa_to_codons = get_dict_list()\n",
        "    print(aa_to_codons)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tKnam_sWLU0"
      },
      "source": [
        "### Idea of solution\n",
        "\n",
        "The `get_dict_list()` function generates a dictionary that maps each amino acid to a list of corresponding codons. It utilizes the `defaultdict` collection to enhance the efficiency of maintaining counts of these mappings. This function will serve as the backbone for most of the code in this notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZuqW8hH6WLU0"
      },
      "source": [
        "### Discussion\n",
        "\n",
        "The output works as expected, mapping each aminoacid to its corresponding set of codons. This process takes into account the frequency of codon usage in different organisms, which can significantly affect protein expression. In theory, this mapping can be valuable for reverse genetic modifications, where researchers may need to convert amino acids back to potential codons. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUpqicWWWLU0"
      },
      "source": [
        "With the conversion tables at hand, the following should be trivial to solve.\n",
        "\n",
        "4. Fill in function ```rna_to_prot``` in the stub solution to convert a given DNA sequence $s$ into a protein sequence.\n",
        "You may use the dictionaries from exercises 2 and 3. You can test your program with `ATGATATCATCGACGATGTAG`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-07-08T22:04:22.913321Z",
          "start_time": "2019-07-08T22:04:22.906646Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNvwNYcxWLU1",
        "outputId": "3eef4fe9-e1f9-4774-9c06-898ce4be4ecf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MISSTM*\n"
          ]
        }
      ],
      "source": [
        "def rna_to_prot(s):\n",
        "    ''' Returns the corresponding amino acid string from an RNA string '''\n",
        "    protein = ''\n",
        "    # Get codon to amino acid mapping\n",
        "    codon_dict = get_dict()\n",
        "    # Use list comprehension to build the protein string\n",
        "    protein = ''.join(codon_dict[s[i:i + 3]] for i in range(0, len(s), 3) if s[i:i + 3] in codon_dict)\n",
        "    return protein\n",
        "\n",
        "def dna_to_prot(s):\n",
        "    ''' Returns DNA to amino acid string.'''\n",
        "    return rna_to_prot(dna_to_rna(s))\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    print(dna_to_prot('ATGATATCATCGACGATGTAG'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICKnWqzHWLU1"
      },
      "source": [
        "### Idea of solution\n",
        "\n",
        "The `rna_to_prot()` function transcribes an RNA sequence into its corresponding protein sequence by translating each codon (triplet of nucleotides) into its respective amino acid. The `dna_to_prot()` function first converts a DNA sequence to RNA and then translates that RNA into a protein sequence, utilizing the functions that have been defined previously."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqxQbR5tWLU2"
      },
      "source": [
        "### Discussion\n",
        "\n",
        "The output works as expected, including the stop codons. This two-step conversion reflects the central dogma of molecular biology: **DNA → RNA → Protein**. It encapsulates the essential processes of transcription and translation, enabling the analysis of entire gene sequences to predict the resulting proteins."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uw-sHDFWLU2"
      },
      "source": [
        "You may notice that there are $4^3=64$ different codons, but only 20 amino acids. That is, some triplets encode the same amino acid.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLaRRuATWLU2"
      },
      "source": [
        "## Reverse translation\n",
        "\n",
        "It has been observed that among the codons coding the same amino acid, some are more frequent than others. These frequencies can be converted to probabilities. E.g. consider codons `AUU`, `AUC`, and `AUA` that code for amino acid isoleucine.\n",
        "If they are observed, say, 36, 47, 17 times, respectively, to code isoleucine in a dataset, the probability that a random such event is `AUU` $\\to$ isoleucine is 36/100.\n",
        "\n",
        "This phenomenon is called *codon adaptation*, and for our purposes it works as a good introduction to generation of random sequences under constraints.   \n",
        "\n",
        "5. Consider the codon adaptation frequencies in http://htmlpreview.github.io/?https://github.com/csmastersUH/data_analysis_with_python_2020/blob/master/Codon%20usage%20table.html and read them into a ```dict()```, such that for each RNA sequence of length 3, say `AGU`, the hash table stores the probability of that codon among codons encoding the same amino acid.\n",
        "Put your solution in the ```get_probabability_dict``` function. Use the column \"([number])\" to estimate the probabilities, as the two preceding columns contain truncated values.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-07-08T22:04:22.966173Z",
          "start_time": "2019-07-08T22:04:22.956013Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27hI0NtLWLU2",
        "outputId": "8a8dc7ec-5947-4bc2-edbc-c42025642bc5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AAA: 0.434049\tAAC: 0.529633\tAAG: 0.565951\tAAU: 0.470367\tACA: 0.284188\tACC: 0.355232\n",
            "ACG: 0.113812\tACU: 0.246769\tAGA: 0.214658\tAGC: 0.239938\tAGG: 0.211091\tAGU: 0.149602\n",
            "AUA: 0.169062\tAUC: 0.469866\tAUG: 1.000000\tAUU: 0.361072\tCAA: 0.265017\tCAC: 0.581485\n",
            "CAG: 0.734983\tCAU: 0.418515\tCCA: 0.276603\tCCC: 0.323470\tCCG: 0.113196\tCCU: 0.286731\n",
            "CGA: 0.108812\tCGC: 0.183777\tCGG: 0.201554\tCGU: 0.080108\tCUA: 0.071380\tCUC: 0.195577\n",
            "CUG: 0.395702\tCUU: 0.131716\tGAA: 0.422453\tGAC: 0.535458\tGAG: 0.577547\tGAU: 0.464542\n",
            "GCA: 0.228121\tGCC: 0.399781\tGCG: 0.106176\tGCU: 0.265922\tGGA: 0.249922\tGGC: 0.337109\n",
            "GGG: 0.249882\tGGU: 0.163087\tGUA: 0.116577\tGUC: 0.238306\tGUG: 0.463346\tGUU: 0.181770\n",
            "UAA: 0.297019\tUAC: 0.556662\tUAG: 0.236738\tUAU: 0.443338\tUCA: 0.150517\tUCC: 0.217960\n",
            "UCG: 0.054398\tUCU: 0.187586\tUGA: 0.466243\tUGC: 0.543843\tUGG: 1.000000\tUGU: 0.456157\n",
            "UUA: 0.076568\tUUC: 0.535866\tUUG: 0.129058\tUUU: 0.464134\n"
          ]
        }
      ],
      "source": [
        "def get_probability_dict():\n",
        "    '''\n",
        "    Fetches probabilities for all codons with respect to their amino acid into a dictionary.\n",
        "    {'AAA': 0.434049, 'AAC': 0.529633, 'AAG': 0.565951, ...}\n",
        "    '''\n",
        "    html_content = get_table()\n",
        "    pre_content = re.search(r'<pre>(.*?)</pre>', html_content, re.DOTALL)  # Find all codon lines in the <pre> tag\n",
        "    if pre_content:\n",
        "        pre_data = pre_content.group(1)\n",
        "        # Initialize dictionaries to hold counts and probabilities\n",
        "        codon_dict = get_dict()\n",
        "        codon_counts = defaultdict(int)\n",
        "        amino_acid_counts = defaultdict(int)\n",
        "        # Find all matches for codons, amino acids, and counts\n",
        "        pattern = r'([AUGC]{3})\\s+([A-Z\\*])\\s+.*?\\s*\\(\\s*(\\d+)\\s*\\)'\n",
        "        matches = re.findall(pattern, pre_data)\n",
        "        # Calculate the counts\n",
        "        for codon, amino_acid, count in matches:\n",
        "            count = int(count)  \n",
        "            codon_counts[codon] += count\n",
        "            amino_acid_counts[amino_acid] += count\n",
        "        # Calculate probabilities\n",
        "        probability_dict = {}\n",
        "        for codon, count in codon_counts.items():\n",
        "            probability = count / amino_acid_counts[codon_dict[codon]]\n",
        "            probability_dict[codon] = probability\n",
        "        return probability_dict\n",
        "    return {}\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    codon_to_prob = get_probability_dict()\n",
        "    items = sorted(codon_to_prob.items(), key=lambda x: x[0])\n",
        "    for i in range(1 + len(items)//6):\n",
        "        print('\\t'.join(\n",
        "            f'{k}: {v:.6f}'\n",
        "            for k, v in items[i*6:6+i*6]\n",
        "        ))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x53dgZYDWLU4"
      },
      "source": [
        "### Idea of solution\n",
        "\n",
        "The `get_probability_dict()` function computes the probability of each codon based on counts extracted from the Codon Usage Table. It leverages previous building blocks for fetching the Codon Usage Table, parsing the HTML data into numeric data, and then performing **counting** and **probability computing**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwjuItA0WLU4"
      },
      "source": [
        "### Discussion\n",
        "\n",
        "The output works as expected: it is a clean table of probabilities for each codon separate from their corresponding amino acid that determines the probability distributions. By selecting codons that are most likely to be translated efficiently in a given organism, this knowledge will enhance protein expression for subsequent function definitions in this notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n95rbseDWLU4"
      },
      "source": [
        "Now you should have everything in place to easily solve the following.\n",
        "\n",
        "\n",
        "6. Write a class ```ProteinToMaxRNA``` with a ```convert``` method which converts a protein sequence into the most likely RNA sequence to be the source of this protein. Run your program with `LTPIQNRA`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-07-08T22:04:23.000743Z",
          "start_time": "2019-07-08T22:04:22.992108Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGaWbHOVWLU4",
        "outputId": "ceffae4a-eafe-4548-94cb-3a1775bf0ae1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CUGACCCCCAUCCAGAACAGAGCC\n"
          ]
        }
      ],
      "source": [
        "class ProteinToMaxRNA:\n",
        "    ''' Maps a protein sequence into its most likely RNA sequence. '''\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def convert(self, s):\n",
        "        ''' 'LTPIQNRA' -> 'CUGACCCCCAUCCAGAACAGAGCC' '''\n",
        "        # Get amino acid to codon and probability for all codons dictionaries\n",
        "        protein_map = get_dict_list()\n",
        "        codon_probability = get_probability_dict()\n",
        "        RNA = []\n",
        "        for protein in s:\n",
        "            codons = protein_map[protein]\n",
        "            # Select the codon with the maximum probability\n",
        "            max_codon = max(codons, key=lambda codon: codon_probability.get(codon, 0))\n",
        "            RNA.append(max_codon)\n",
        "        return ''.join(RNA)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    protein_to_rna = ProteinToMaxRNA()\n",
        "    print(protein_to_rna.convert('LTPIQNRA'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qw-TTkGvWLU5"
      },
      "source": [
        "### Idea of solution\n",
        "\n",
        "This class and method generate the most probable RNA sequence for a given protein using codon probabilities. While the probabilities can be utilized for better data wrangling, for now, it suffices to select the codon with the maximum probability. The `max()` method, along with a lambda function, proves useful for extracting the maximum probability from the codon dictionary."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OSgC9NtWLU6"
      },
      "source": [
        "### Discussion\n",
        "\n",
        "Because of its limited scope (max sampling), the output sequence is expected to be random yet with a low degree of variance. This approach will not be used anymore in this notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CaO60IR-WLU6"
      },
      "source": [
        "Now we are almost ready to produce random RNA sequences that code a given protein sequence. For this, we need a subroutine to *sample from a probability distribution*. Consider our earlier example of probabilities 36/100, 47/100, and 17/100 for `AUU`, `AUC`, and `AUA`, respectively.\n",
        "Let us assume we have a random number generator ```random()``` that returns a random number from interval $[0,1)$. We may then partition the unit interval according to cumulative probabilities to $[0,36/100), [36/100,83/100), [83/100,1)$, respectively. Depending which interval the number ```random()``` hits, we select the codon accordingly.\n",
        "\n",
        "7. Write a function ```random_event``` that chooses a random event, given a probability distribution (set of events whose probabilities sum to 1).\n",
        "You can use function ```random.uniform``` to produce values uniformly at random from the range $[0,1)$. The distribution should be given to your function as a dictionary from events to their probabilities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-07-08T22:04:23.036655Z",
          "start_time": "2019-07-08T22:04:23.030067Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HeqhIF10WLU6",
        "outputId": "663d0f3a-66b5-4aaf-fc7f-be0fc6f69b82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "C, T, A, G, C, T, C, G, T, A, G, C, T, T, A, T, A, C, C, T, T, T, G, G, T, G, C, A, T\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "def random_event(dist):\n",
        "    '''\n",
        "    Takes as input a dictionary from events to their probabilities.\n",
        "    Returns a random event sampled according to the given distribution.\n",
        "    The probabilities must sum to 1.0\n",
        "    Ex: T, A, G, T, C, C, T, C, etc.\n",
        "    '''\n",
        "    events, weights = zip(*dist.items())\n",
        "    return random.choices(events, weights=weights)[0]\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    distribution = dict(zip('ACGT', [0.10, 0.35, 0.15, 0.40]))\n",
        "    print(', '.join(random_event(distribution) for _ in range(29)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmYE6J8YWLU7"
      },
      "source": [
        "### Idea of solution\n",
        "\n",
        "The `random_event()` function randomly selects an event (a nucleotide) based on a given probability distribution. It efficiently utilizes the Python `random` library to sample uniformly using the weights provided through the distribution dictionary."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2OsjEo3WLU7"
      },
      "source": [
        "### Discussion\n",
        "\n",
        "The `random_event()` function forms the basis for creating probabilistic models that will be further explored in this notebook. Random sampling is essential in computational biology for simulating biological processes, such as mutation rates or gene expression."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SPVVqjHWLU8"
      },
      "source": [
        "With this general routine, the following should be easy to solve.\n",
        "\n",
        "8. Write a class ```ProteinToRandomRNA``` to produce a random RNA sequence encoding the input protein sequence according to the input codon adaptation probabilities. The actual conversion is done through the ```convert``` method. Run your program with `LTPIQNRA`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-07-08T22:04:23.073660Z",
          "start_time": "2019-07-08T22:04:23.067966Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpyauTp3WLU8",
        "outputId": "6bbc5e24-5a6f-44ae-91f8-b2292a82444d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CUGACCCCCAUCCAGAAUAGGGCC\n"
          ]
        }
      ],
      "source": [
        "class ProteinToRandomRNA:\n",
        "    ''' Maps a protein sequence into a random RNA sequence based on probabilities. '''\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def convert(self, s):\n",
        "        ''' \"LTPIQNRA\" -> \"CUGACUCCUAUCCAGAACCGGGCC\" '''\n",
        "        # Get amino acid to codon and probability for all codons dictionaries\n",
        "        protein_map = get_dict_list()\n",
        "        codon_probability = get_probability_dict()\n",
        "        RNA = []\n",
        "        for protein in s:\n",
        "            codons = protein_map[protein]\n",
        "            # Create a probability distribution for the codons\n",
        "            probability_distribution = [codon_probability[codon] for codon in codons]\n",
        "            RNA.append(random_event(dict(zip(codons, probability_distribution))))\n",
        "        return ''.join(RNA)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    protein_to_random_codons = ProteinToRandomRNA()\n",
        "    print(protein_to_random_codons.convert('LTPIQNRA'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8gvh9enWLU9"
      },
      "source": [
        "### Idea of solution\n",
        "\n",
        "This class and method generate a random RNA sequence for a given protein, taking into account `Codon Usage Probabilities` and their extracted distributions of each amino acid. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xy0hU7xpWLU9"
      },
      "source": [
        "### Discussion\n",
        "\n",
        "The output works as expected with no clear sequential relationships yet (which will be provided by Markov Chains). Even with this limitation, through the lens of probability, we can now explore the generative potential of having genetic data. This allows us to create diverse synthetic RNA sequences based on specific protein sequences, which are crucial in real-life scenarios such as genetic engineering."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Wy9NWMHWLU9"
      },
      "source": [
        "## Generating DNA sequences with higher-order Markov chains\n",
        "\n",
        "We will now reuse the machinery derived above in a related context. We go back to DNA sequences, and consider some easy statistics that can be used to characterize the sequences.\n",
        "First, just the frequencies of bases $\\texttt{A}$, $\\texttt{C}$, $\\texttt{G}$, $\\texttt{T}$ may reveal the species from which the input DNA originates; each species has a different base composition that has been formed during evolution.\n",
        "More interestingly, the areas where DNA to RNA transcription takes place (coding region) have an excess of $\\texttt{C}$ and $\\texttt{G}$ over $\\texttt{A}$ and $\\texttt{T}$. To detect such areas a common routine is to just use a *sliding window* of fixed size, say $k$, and compute for each window position\n",
        "$T[i..i+k-1]$ the base frequencies, where $T[1..n]$ is the input DNA sequence. When sliding the window from  $T[i..i+k-1]$ to $T[i+1..i+k]$ frequency $f(T[i])$ gets decreases by one and $f(T[i+k])$ gets increased by one.\n",
        "\n",
        "9. Write a *generator* ```sliding_window``` to compute sliding window base frequencies so that each moving of the window takes constant time. We saw in the beginning of the course one way how to create generators using\n",
        "  generator expression. Here we use a different way. For the function ```sliding_window``` to be a generator, it must have at least   one ```yield``` expression, see [https://docs.python.org/3/reference/expressions.html#yieldexpr](https://docs.python.org/3/reference/expressions.html#yieldexpr).\n",
        "  \n",
        "  Here is an example of a generator expression that works similarily to the built in `range` generator:\n",
        "  ```Python\n",
        "  def range(a, b=None, c=1):\n",
        "      current = 0 if b == None else a\n",
        "      end = a if b == None else b\n",
        "      while current < end:\n",
        "          yield current\n",
        "          current += c\n",
        "  ```\n",
        "  A yield expression can be used to return a value and *temporarily* return from the function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-07-08T22:04:23.111365Z",
          "start_time": "2019-07-08T22:04:23.100858Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5tBix70WLU9",
        "outputId": "f73ad5ba-493f-459c-b75b-3048ee96f294"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'A': 0, 'C': 3, 'G': 0, 'T': 1}\n",
            "{'A': 0, 'C': 3, 'G': 1, 'T': 0}\n",
            "{'A': 1, 'C': 2, 'G': 1, 'T': 0}\n",
            "{'A': 1, 'C': 2, 'G': 1, 'T': 0}\n",
            "{'A': 1, 'C': 1, 'G': 2, 'T': 0}\n",
            "{'A': 1, 'C': 1, 'G': 2, 'T': 0}\n",
            "{'A': 0, 'C': 2, 'G': 2, 'T': 0}\n",
            "{'A': 0, 'C': 2, 'G': 2, 'T': 0}\n",
            "{'A': 0, 'C': 2, 'G': 1, 'T': 1}\n",
            "{'A': 0, 'C': 2, 'G': 0, 'T': 2}\n",
            "{'A': 0, 'C': 1, 'G': 1, 'T': 2}\n",
            "{'A': 0, 'C': 1, 'G': 1, 'T': 2}\n",
            "{'A': 0, 'C': 2, 'G': 1, 'T': 1}\n"
          ]
        }
      ],
      "source": [
        "def sliding_window(s, k):\n",
        "    '''\n",
        "    Returns a generator that can be iterated over\n",
        "    starting positions of a k-window in the sequence.\n",
        "    Each starting position yields the nucleotide frequencies in the window as a dictionary.\n",
        "    {'A': 0, 'C': 3, 'G': 0, 'T': 1}\n",
        "    ...\n",
        "    {'A': 0, 'C': 2, 'G': 1, 'T': 1}\n",
        "    '''\n",
        "    nucleotide_freqs = {nucleotide: 0 for nucleotide in 'ACGT'}\n",
        "    # Initialize the frequency count for the first window\n",
        "    for nucleotide in s[:k]:\n",
        "        nucleotide_freqs[nucleotide] += 1\n",
        "\n",
        "    yield nucleotide_freqs\n",
        "\n",
        "    # Slide the window across the sequence\n",
        "    for i in range(1, len(s) - k + 1):\n",
        "        nucleotide_freqs[s[i - 1]] -= 1  # Remove count of the outgoing nucleotide\n",
        "        nucleotide_freqs[s[i + k - 1]] += 1  # Add count of the incoming nucleotide\n",
        "        yield nucleotide_freqs  # Yield the updated frequencies\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    s = 'TCCCGACGGCCTTGCC'\n",
        "    for d in sliding_window(s, 4):\n",
        "        print(d)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwpvuqJNWLU-"
      },
      "source": [
        "### Idea of solution\n",
        "\n",
        "The `sliding_window()` function yields a temporary value that provides nucleotide frequencies for overlapping windows of length **k** across the sequence. It leverages the optimal capabilities of generator expressions, allowing it to handle sequences of arbitrary length and at an arbitrary phase without consuming as much memory as conventional list processing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ks5eroGWLU-"
      },
      "source": [
        "### Discussion\n",
        "\n",
        "The output dictionaries work as expected. While the `sliding_window()` function will not be further utilized in this notebook, it introduces a more sophisticated approach for analyzing genetic data, which is inherently sequential. Sliding windows are a common approach in sequence analysis, particularly in genomics, but also in all sorts of time-series and signal-processing duties. In our particular context, examining nucleotide frequencies can help identify regions of significance, such as motifs or other important sequence features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xd4CPpfxWLU_"
      },
      "source": [
        "\n",
        "Our models so far have been so-called *zero-order* models, as each event has been independent of other events. With sequences, the dependencies of events are naturally encoded by their *contexts*. Considering that a sequence is produced from left-to-right, a *first-order* context for $T[i]$ is $T[i-1]$, that is, the immediately preceding symbol. *First-order Markov chain* is a sequence produced by generating $c=T[i]$ with the probability of event of seeing symbol $c$ after previously generated symbol $a=T[i-1]$. The first symbol of the chain is sampled according to the zero-order model.  \n",
        "The first-order model can naturally be extended to contexts of length $k$, with $T[i]$ depending on $T[i-k..i-1]$. Then the first $k$ symbols of the chain are sampled according to the zero-order model.  The following assignments develop the routines to work with the *higher-order Markov chains*.\n",
        "In what follows, a $k$-mer is a substring $T[i..i+k-1]$ of the sequence at an arbitrary position.\n",
        "\n",
        "10. Write function ```context_list``` that given an input DNA sequence $T$ associates to each $k$-mer $W$ the concatenation of all symbols $c$ that appear after context $W$ in $T$, that is, $T[i..i+k]=Wc$. For example, <span style=\"color:red; font:courier;\">GA</span> is associated to <span style=\"color:blue; font: courier;\">TCT</span> in $T$=<span style=\"font: courier;\">AT<span style=\"color:red;\">GA</span><span style=\"color:blue;\">T</span>ATCATC<span style=\"color:red;\">GA</span><span style=\"color:blue;\">C</span><span style=\"color:red;\">GA</span><span style=\"color:blue;\">T</span>GTAG</span>, when $k=2$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-07-08T22:04:23.168108Z",
          "start_time": "2019-07-08T22:04:23.162648Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wIccyDfaWLU_",
        "outputId": "00f905de-5bd0-4cdc-e585-70d48892d79e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'AT': 'GACCC', 'TG': 'A', 'GA': 'TCT', 'TA': 'TG', 'TC': 'AGT', 'CA': 'T', 'CG': 'AA', 'AC': 'G', 'CT': 'A'}\n"
          ]
        }
      ],
      "source": [
        "def context_list(s, k):\n",
        "    '''\n",
        "    Returns a dictionary mapping k-mers to their following nucleotides.\n",
        "    {'AC': 'G', 'AT': 'GACCC', ..., }\n",
        "    '''\n",
        "    wc = defaultdict(list)\n",
        "    if k == 0:\n",
        "        return {'': s}\n",
        "    # Iterate through the string, stopping early enough to avoid index errors\n",
        "    for i in range(len(s) - k):\n",
        "        current_kmer = s[i:i + k]\n",
        "        following_symbol = s[i + k]\n",
        "        wc[current_kmer].append(following_symbol)\n",
        "\n",
        "    return {key: ''.join(value) for key, value in wc.items()}\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    k = 2\n",
        "    s = 'ATGATATCATCGACGATCTAG'\n",
        "    d = context_list(s, k)\n",
        "    print(d)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AmbPlkwOWLVA"
      },
      "source": [
        "### Idea of solution\n",
        "\n",
        "The `context_list()` function creates a mapping of k-mers to the nucleotides that immediately follow them in the sequence. It utilizes the capabilities of the `defaultdict` object to efficiently keep track of k-mers and their corresponding following nucleotides."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFo1SEqAWLVA"
      },
      "source": [
        "### Discussion\n",
        "\n",
        "The resulting dictionary works as expected, providing the foundations for context-based models for sequence analysis, and enabling the prediction of nucleotide behavior based on preceding sequences. In this simple exercise using genomic data, we can gain insight into how sequences are formed in a manner that is not stochastic but probabilistic."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGVBelf4WLVA"
      },
      "source": [
        "11. With the above solution, write function ```context_probabilities``` to count the frequencies of symbols in each context and convert these frequencies into probabilities. Run `context_probabilities` with $T=$ `ATGATATCATCGACGATGTAG` and $k$ values 0 and 2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-07-08T22:04:23.218964Z",
          "start_time": "2019-07-08T22:04:23.213773Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vlphTtAWLVA",
        "outputId": "340a5935-23de-4410-8b98-ccf46765e2b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'': {'A': 0.3333333333333333, 'C': 0.19047619047619047, 'G': 0.19047619047619047, 'T': 0.2857142857142857}}\n",
            "{'AT': {'A': 0.2, 'C': 0.6, 'G': 0.2, 'T': 0.0}, 'TG': {'A': 1.0, 'C': 0.0, 'G': 0.0, 'T': 0.0}, 'GA': {'A': 0.0, 'C': 0.3333333333333333, 'G': 0.0, 'T': 0.6666666666666666}, 'TA': {'A': 0.0, 'C': 0.0, 'G': 0.5, 'T': 0.5}, 'TC': {'A': 0.3333333333333333, 'C': 0.0, 'G': 0.3333333333333333, 'T': 0.3333333333333333}, 'CA': {'A': 0.0, 'C': 0.0, 'G': 0.0, 'T': 1.0}, 'CG': {'A': 1.0, 'C': 0.0, 'G': 0.0, 'T': 0.0}, 'AC': {'A': 0.0, 'C': 0.0, 'G': 1.0, 'T': 0.0}, 'CT': {'A': 1.0, 'C': 0.0, 'G': 0.0, 'T': 0.0}}\n"
          ]
        }
      ],
      "source": [
        "def context_probabilities(s, k):\n",
        "    '''\n",
        "    Computes probabilities of nucleotides following each k-mer in the sequence.\n",
        "    '''\n",
        "    if k == 0:  # Resulting context is equal to input sequence\n",
        "        return {'': {nucleotide: s.count(nucleotide) / len(s) for nucleotide in 'ACGT'}}\n",
        "\n",
        "    context = context_list(s, k)\n",
        "    probabilities = {}\n",
        "    kmer_freqs = {}\n",
        "    for kmer, follows in context.items():\n",
        "        total_follows = len(follows)\n",
        "        for nucleotide in 'ACGT':\n",
        "            kmer_freqs[nucleotide] = follows.count(nucleotide)\n",
        "        probabilities[kmer] = {nucleotide: count / total_follows for nucleotide, count in kmer_freqs.items()}\n",
        "\n",
        "    return probabilities\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    s = 'ATGATATCATCGACGATCTAG'\n",
        "    print(context_probabilities(s, 0))\n",
        "    print(context_probabilities(s, 2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LefGA6XWLVB"
      },
      "source": [
        "### Idea of solution\n",
        "\n",
        "The `context_probabilities()` function calculates the probabilities of each nucleotide following each k-mer within the sequence. It essentially utilizes the contextual frequency analysis facilitated by the preceding `context_list()` function to derive these probabilities."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YuittCsZWLVC"
      },
      "source": [
        "### Discussion\n",
        "\n",
        "The output dictionary correctly maps the probabilistic relationships to the provided input sequences. Understanding the conditional probabilities of nucleotide occurrences enhances our grasp of sequence dynamics and facilitates the development of sequence models, such as `Markov Chains`, which can illustrate the inheritance of genetic traits. This, in turn, is important because sequential data implies causal relationships that can be explored in increasingly complex contexts, along with their associated probability distributions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tMvMSH4WLVC"
      },
      "source": [
        "12. With the above solution and the function ```random_event``` from the earlier exercise, write class ```MarkovChain```. Its ```generate``` method should generate a random DNA sequence following the original $k$-th order Markov chain probabilities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-07-08T22:04:23.279315Z",
          "start_time": "2019-07-08T22:04:23.253983Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-lGmCCOWLVD",
        "outputId": "91667476-85ee-4686-ad34-b0ec0195ca56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GGTAGTATCG\n"
          ]
        }
      ],
      "source": [
        "class MarkovChain:\n",
        "    ''' Generates sequences based on a Markov Chain model'''\n",
        "    def __init__(self, zeroth, kth, k=2):\n",
        "        self.k = k\n",
        "        self.zeroth = zeroth\n",
        "        self.kth = kth\n",
        "\n",
        "    def generate(self, n, seed=None):\n",
        "        ''' Generate a random sequence of length n using the Markov Chain model '''\n",
        "        if n == 0:\n",
        "            return []\n",
        "\n",
        "        if seed is not None:\n",
        "            random.seed(seed)\n",
        "\n",
        "        start = random_event(self.zeroth)\n",
        "        sequence = [start]\n",
        "\n",
        "        while n > len(sequence):\n",
        "            step = ''.join(sequence[-self.k:])\n",
        "            if step in self.kth:\n",
        "                next_nucleotide = random_event(self.kth[step])\n",
        "            else:\n",
        "                next_nucleotide = random_event(self.zeroth)\n",
        "            sequence.append(next_nucleotide)\n",
        "\n",
        "        return ''.join(sequence)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    zeroth = {'A': 0.2, 'C': 0.19, 'T': 0.31, 'G': 0.3}\n",
        "    kth = {'GT': {'A': 1.0, 'C': 0.0, 'T': 0.0, 'G': 0.0},\n",
        "           'CA': {'A': 0.0, 'C': 0.0, 'T': 1.0, 'G': 0.0},\n",
        "           'TC': {'A': 0.5, 'C': 0.0, 'T': 0.0, 'G': 0.5},\n",
        "           'GA': {'A': 0.0, 'C': 0.3333333333333333, 'T': 0.6666666666666666, 'G': 0.0},\n",
        "           'TG': {'A': 0.5, 'C': 0.0, 'T': 0.5, 'G': 0.0},\n",
        "           'AT': {'A': 0.2, 'C': 0.4, 'T': 0.0, 'G': 0.4},\n",
        "           'TA': {'A': 0.0, 'C': 0.0, 'T': 0.5, 'G': 0.5},\n",
        "           'AC': {'A': 0.0, 'C': 0.0, 'T': 0.0, 'G': 1.0},\n",
        "           'CG': {'A': 1.0, 'C': 0.0, 'T': 0.0, 'G': 0.0}}\n",
        "    n = 10\n",
        "    seed = 0\n",
        "    mc = MarkovChain(zeroth, kth)\n",
        "    print(mc.generate(n, seed))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8qkOb5ZWLVE"
      },
      "source": [
        "### Idea of solution\n",
        "\n",
        "This class and method generate random nucleotide sequences using a `Markov Chains` based on given zeroth and k-th probabilities. It effectively utilizes previously defined functions to create sequences that are no longer uniformly random, providing more coherent contextual information. This process is facilitated by the combined use of random event sampling and the pre-defined zeroth and k-th probability distributions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TEj-VuzWLVE"
      },
      "source": [
        "### Discussion\n",
        "\n",
        "The sequence exhibits the usefulness of `Markov Chains` as modeling tools for computational biology. In theory, this approach can simulate how genes evolve over generations and can be used to model various aspects of genetic similarities and variations across species. Moreover, this implementation of `Markov Chains` signals their utility beyond the biological domain, serving as generative tools for a wide range of applications."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vLGL03GWLVF"
      },
      "source": [
        "If you have survived so far without problems, please run your program a few more times with different inputs. At some point you should get a lookup error in your hash-table! The reason for this is not your code, but the way we defined the model: Some $k$-mers may not be among the training data (input sequence $T$), but such can be generated as the first $k$-mer that is generated using the zero-order model.  \n",
        "\n",
        "A general approach to fixing such issues with incomplete training data is to use *pseudo counts*. That is, all imaginable events are initialized to frequency count 1.   \n",
        "\n",
        "13. Write a new solution `context_pseudo_probabilities` based on the solution to problem 11. But this time use pseudo counts in order to obtain a $k$-th order Markov chain that can assign a probability for any DNA sequence. You may use the standard library function `itertools.product` to iterate over all $k$-mer of given length (`product(\"ACGT\", repeat=k)`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-07-08T22:04:23.303566Z",
          "start_time": "2019-07-08T22:04:23.296028Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nifGjkcwWLVF",
        "outputId": "1750589e-a21a-423b-a160-1b9b6cd38bec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "zeroth: {'A': 0.32, 'C': 0.16, 'G': 0.24, 'T': 0.28}\n",
            "AA: {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}\n",
            "AC: {'A': 0.2, 'C': 0.2, 'G': 0.4, 'T': 0.2}\n",
            "AG: {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}\n",
            "AT: {'A': 0.2222222222222222, 'C': 0.3333333333333333, 'G': 0.3333333333333333, 'T': 0.1111111111111111}\n",
            "CA: {'A': 0.2, 'C': 0.2, 'G': 0.2, 'T': 0.4}\n",
            "CC: {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}\n",
            "CG: {'A': 0.5, 'C': 0.16666666666666666, 'G': 0.16666666666666666, 'T': 0.16666666666666666}\n",
            "CT: {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}\n",
            "GA: {'A': 0.14285714285714285, 'C': 0.2857142857142857, 'G': 0.14285714285714285, 'T': 0.42857142857142855}\n",
            "GC: {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}\n",
            "GG: {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}\n",
            "GT: {'A': 0.4, 'C': 0.2, 'G': 0.2, 'T': 0.2}\n",
            "TA: {'A': 0.16666666666666666, 'C': 0.16666666666666666, 'G': 0.3333333333333333, 'T': 0.3333333333333333}\n",
            "TC: {'A': 0.3333333333333333, 'C': 0.16666666666666666, 'G': 0.3333333333333333, 'T': 0.16666666666666666}\n",
            "TG: {'A': 0.3333333333333333, 'C': 0.16666666666666666, 'G': 0.16666666666666666, 'T': 0.3333333333333333}\n",
            "TT: {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}\n",
            "\n",
            " TGATGATTTTCGTGCAGGTT\n"
          ]
        }
      ],
      "source": [
        "def context_pseudo_probabilities(s, k):\n",
        "    '''\n",
        "    Computes pseudo probabilities of nucleotides following each k-mer.\n",
        "    '''\n",
        "    # To count occurrences of k-mers and their following nucleotides\n",
        "    context = context_list(s, k)\n",
        "    probabilities = {}\n",
        "    # Generate all possible k-mers of length k\n",
        "    all_kmers = [''.join(kmer) for kmer in product('ACGT', repeat=k)]\n",
        "    for kmer in all_kmers:\n",
        "        if kmer in context:\n",
        "            # '' is fallback in case no key is found (otherwise known as zeroth)\n",
        "            follows = context.get(kmer, '')\n",
        "            # Add pseudo count for each nucleotide base 'ACGT'\n",
        "            total_follows = len(follows) + 4\n",
        "            # Count occurrences of nucleotides that follow the k-mer, add pseudo-count then calculate probabilities\n",
        "            probabilities[kmer] = {nucleotide: (follows.count(nucleotide) + 1) / total_follows for nucleotide in 'ACGT'}\n",
        "        else:\n",
        "            probabilities[kmer] = {nucleotide: 0.25 for nucleotide in 'ACGT'}\n",
        "\n",
        "    return probabilities\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    k = 2\n",
        "    s = 'ATGATATCATCGACGATGTAG'\n",
        "    kth = context_pseudo_probabilities(s, k)\n",
        "    zeroth = context_pseudo_probabilities(s, 0)['']\n",
        "    print(f'zeroth: {zeroth}')\n",
        "    print('\\n'.join(f'{k}: {dict(v)}' for k, v in kth.items()))\n",
        "\n",
        "    print('\\n', MarkovChain(zeroth, kth, k).generate(20))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mac_ue_fWLVF"
      },
      "source": [
        "### Idea of solution\n",
        "\n",
        "The `context_pseudo_probabilities()` function computes pseudo probabilities for nucleotides that follow each k-mer, incorporating pseudo-counts to enhance reliability in small datasets. \n",
        "To calculate all possible k-mers, we utilize the `product` tool from the `itertools` library."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RABcWmcIWLVG"
      },
      "source": [
        "### Discussion\n",
        "\n",
        "In biological data, some k-mers may be underrepresented (as exemplified here by codons *AA*, *AG*, *CC*, *GC*, *GG* and *TT*). By using pseudo-counts, the `context_pseudo_probabilities()` function mitigates the impact of sparse data, providing more robust probability and paving the way for motif discovery, where accurate probability assessments are crucial."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIB1n7dPWLVG"
      },
      "source": [
        "14. Write class ```MarkovProb``` that given the $k$-th order Markov chain developed above to the constructor, its method ```probability``` computes the probability of a given input DNA sequence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WADozsmSWLVG",
        "outputId": "b0171997-711d-49b9-ce07-e4aef44ab320"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Probability of sequence ATGATATCATCGACGATGTAG is 2.831270190340017e-10\n"
          ]
        }
      ],
      "source": [
        "class MarkovProb:\n",
        "    ''' Computes probabilities based on a Markov Chain '''\n",
        "    def __init__(self, k, zeroth, kth):\n",
        "        self.k = k\n",
        "        self.zeroth = zeroth\n",
        "        self.kth = kth\n",
        "\n",
        "    def probability(self, s):\n",
        "        ''' Computes the probability of a given sequence based on the Markov model '''\n",
        "        if len(s) == 1:\n",
        "            return self.zeroth[s]\n",
        "\n",
        "        probabilities = 1.0\n",
        "        # Handle first k-mer\n",
        "        for nucleotide in range(self.k):\n",
        "            # Multiply by zero-order probabilities\n",
        "            probabilities *= self.zeroth[s[nucleotide]]\n",
        "        # Handle k-th order probabilities\n",
        "        for i in range(len(s) - self.k):\n",
        "            kmer = s[i:i + self.k]\n",
        "            next_nucleotide = s[i + self.k]\n",
        "            probabilities *= self.kth[kmer][next_nucleotide]\n",
        "\n",
        "        return probabilities\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    k = 2\n",
        "    kth = context_pseudo_probabilities('ATGATATCATCGACGATGTAG', k)\n",
        "    zeroth = context_pseudo_probabilities('ATGATATCATCGACGATGTAG', 0)['']\n",
        "    mc = MarkovProb(2, zeroth, kth)\n",
        "    s = 'ATGATATCATCGACGATGTAG'\n",
        "    print(f'Probability of sequence {s} is {mc.probability(s)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UpNDDeMaWLVH"
      },
      "source": [
        "### Idea of solution\n",
        "\n",
        "This class and method calculate the probability of observing a specific nucleotide sequence based on zeroth order and k-th order Markov probabilities. It is important to note that zeroth order and k-th order probabilities must be computed (by utilizing the `context_pseudo_probabilities()` function) prior to using this method."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRSn3_ZfWLVH"
      },
      "source": [
        "### Discussion\n",
        "\n",
        "Probabilities derived from Markov models are instrumental in predicting the likelihood of specific gene arrangements and their potential occurrences in population genetics. In this instance, even for such a short sequence, the predicted probability is expected an extremely low value. This outcome is a direct consequence of the principles of conditional probability."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSFVynasWLVH"
      },
      "source": [
        "With the last assignment you might end up in trouble with precision, as multiplying many small probabilities gives a really small number in the end. There is an easy fix by using so-called log-transform.\n",
        "Consider computation of $P=s_1 s_2 \\cdots s_n$, where $0\\leq s_i\\leq 1$ for each $i$. Taking logarithm in base 2 from both sides gives $\\log _2 P= \\log _2 (s_1 s_2 \\cdots s_n)=\\log_2 s_1 + \\log_2 s_2 + \\cdots \\log s_n= \\sum_{i=1}^n \\log s_i$, with repeated application of the property that the logarithm of a multiplication of two numbers is the sum of logarithms of the two numbers taken separately. The results is abbreviated as log-probability.\n",
        "\n",
        "15. Write class ```MarkovLog``` that given the $k$-th order Markov chain developed above to the constructor, its method ```log_probability``` computes the log-probability of a given input DNA sequence. Run your program with $T=$ `ATGATATCATCGACGATGTAG` and $k=2$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-07-08T22:04:23.390453Z",
          "start_time": "2019-07-08T22:04:23.379760Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBOR0836WLVH",
        "outputId": "308e9521-99d5-41e8-dce5-589d504b1502"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Log probability of sequence ATGATATCATCGACGATGTAG is -31.717831515538315\n"
          ]
        }
      ],
      "source": [
        "class MarkovLog:\n",
        "    ''' Computes log probabilities based on a Markov Chain '''\n",
        "    def __init__(self, k, zeroth, kth):\n",
        "        self.k = k\n",
        "        self.zeroth = zeroth\n",
        "        self.kth = kth\n",
        "\n",
        "    def log_probability(self, s):\n",
        "        ''' Computes the log probability of a given sequence '''\n",
        "        if len(s) == 1:\n",
        "            return np.log2(self.zeroth[s])\n",
        "        # Log2 of 1 is 0 so we initialize the log probability to zero\n",
        "        prob = 0.\n",
        "        # Handle first k-mer\n",
        "        for nucleotide in range(self.k):\n",
        "            # Sum of zero-order log probabilities\n",
        "            prob += np.log2(self.zeroth[s[nucleotide]])\n",
        "        # Handle k-th order probabilities\n",
        "        for i in range(len(s) - self.k):\n",
        "            kmer = s[i:i + self.k]\n",
        "            next_nucleotide = s[i + self.k]\n",
        "            prob += np.log2(self.kth[kmer][next_nucleotide])\n",
        "\n",
        "        return prob\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    k = 2\n",
        "    kth = context_pseudo_probabilities('ATGATATCATCGACGATGTAG', k)\n",
        "    zeroth = context_pseudo_probabilities('ATGATATCATCGACGATGTAG', 0)['']\n",
        "    mc = MarkovLog(2, zeroth, kth)\n",
        "    s = 'ATGATATCATCGACGATGTAG'\n",
        "    print(f'Log probability of sequence {s} is {mc.log_probability(s)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adtqd6u0WLVI"
      },
      "source": [
        "### Idea of solution\n",
        "\n",
        "This class and method compute the log probability of a nucleotide sequence using Markov model probabilities. By converting multiplicative relationships into additive ones, this approach enhances numerical stability and improves readability. The implementation utilizes the `numpy.log2` function to perform the logarithmic calculations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnRETIJFWLVI"
      },
      "source": [
        "### Discussion\n",
        "\n",
        "As expected, it can be seen that the log probability for the same sequence that was used for `Markov Prov` yields a much more significant value for human analysis and comparatives. While they won't be used any further in this notebook, log probabilities are frequently used in sequence alignment and comparative genomics to prevent underflow issues during calculations involving small probabilities, particularly in large datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwOP4WejWLVI"
      },
      "source": [
        "Finally, if you try to use the code so far for very large inputs, you might observe that the concatenation of symbols following a context occupy considerable amount of space. This is unnecessary, as we only need the frequencies.\n",
        "\n",
        "16. Optimize the space requirement of your code from exercise 13 for the $k$-th order Markov chain by replacing the concatenations by direct computations of the frequencies. Implement this as the\n",
        "  ```better_context_probabilities``` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-07-08T22:04:23.422302Z",
          "start_time": "2019-07-08T22:04:23.416330Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qP1kDJjWLVI",
        "outputId": "b843f425-5a07-44c0-f891-c8fe81904dea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AA: {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}\n",
            "AC: {'A': 0.2, 'C': 0.2, 'G': 0.4, 'T': 0.2}\n",
            "AG: {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}\n",
            "AT: {'A': 0.2222222222222222, 'C': 0.3333333333333333, 'G': 0.3333333333333333, 'T': 0.1111111111111111}\n",
            "CA: {'A': 0.2, 'C': 0.2, 'G': 0.2, 'T': 0.4}\n",
            "CC: {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}\n",
            "CG: {'A': 0.5, 'C': 0.16666666666666666, 'G': 0.16666666666666666, 'T': 0.16666666666666666}\n",
            "CT: {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}\n",
            "GA: {'A': 0.14285714285714285, 'C': 0.2857142857142857, 'G': 0.14285714285714285, 'T': 0.42857142857142855}\n",
            "GC: {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}\n",
            "GG: {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}\n",
            "GT: {'A': 0.4, 'C': 0.2, 'G': 0.2, 'T': 0.2}\n",
            "TA: {'A': 0.16666666666666666, 'C': 0.16666666666666666, 'G': 0.3333333333333333, 'T': 0.3333333333333333}\n",
            "TC: {'A': 0.3333333333333333, 'C': 0.16666666666666666, 'G': 0.3333333333333333, 'T': 0.16666666666666666}\n",
            "TG: {'A': 0.3333333333333333, 'C': 0.16666666666666666, 'G': 0.16666666666666666, 'T': 0.3333333333333333}\n",
            "TT: {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}\n"
          ]
        }
      ],
      "source": [
        "def better_context_probabilities(s, k):\n",
        "    '''\n",
        "    Computes improved context probabilities using pseudo-counts.\n",
        "    k-th:\n",
        "    AA: {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25},\n",
        "    AG: {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}, ..., }\n",
        "    '''\n",
        "    # To count occurrences of k-mers and next nucleotides\n",
        "    context_counts = defaultdict(lambda: defaultdict(int))\n",
        "    # Collect context data\n",
        "    for i in range(len(s) - k):\n",
        "        kmer = s[i:i + k]\n",
        "        next_nucleotide = s[i + k]\n",
        "        context_counts[kmer][next_nucleotide] += 1\n",
        "\n",
        "    probabilities = {}\n",
        "    # Generate all possible k-mers of length k\n",
        "    all_kmers = [''.join(kmer) for kmer in product('ACGT', repeat=k)]\n",
        "    for kmer in all_kmers:\n",
        "        # Add pseudo count for each nucleotide base 'ACGT'\n",
        "        total_follows = sum(context_counts[kmer].values()) + 4\n",
        "        # Populate kmer_freqs with counts from context_counts for the current kmer, add pseudo-count then calculate probabilities\n",
        "        probabilities[kmer] = {nucleotide: (context_counts[kmer][nucleotide] + 1) / total_follows for nucleotide in 'ACGT'}\n",
        "\n",
        "    return probabilities\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    k = 2\n",
        "    s = 'ATGATATCATCGACGATGTAG'\n",
        "    d = better_context_probabilities(s, k)\n",
        "    print('\\n'.join(f'{k}: {v}' for k, v in d.items()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXDHNcgzWLVI"
      },
      "source": [
        "### Idea of solution\n",
        "\n",
        "We directly maintain counts of following nucleotides in a nested `defaultdict` (referred to as `context_counts`), which avoids the need to store large lists of nucleotides as strings. Pseudo counts are added directly while generating the probabilities, ensuring that we account for unseen nucleotides without the necessity of storing large suffixes. While the overall flow remains similar, this approach significantly reduces memory usage during the counting phase."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4IEYjluWLVJ"
      },
      "source": [
        "### Discussion\n",
        "\n",
        "The `better_context_probabilities()` function computes context probabilities using a more robust approach than the `pseudo_context_probabilities()` function, ensuring greater reliability in the analysis. As expected, the output itself is identical to the latter, with *AA*, *AG*, *CC*, *GC*, *GG* and *TT* having pseudo-counts for this particular set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNRT4rh0WLVJ"
      },
      "source": [
        "While the earlier approach of explicit concatenation of symbols following a context suffered from inefficient use of space, it does have a benefit of giving another much simpler strategy to sample from the distribution:\n",
        "observe that an element of the concatenation taken uniformly randomly is sampled exactly with the correct probability.\n",
        "\n",
        "17. Revisit the solution 12 and modify it to directly sample from the concatenation of symbols following a context. The function ```np.random.choice``` may be convenient here. Implement the modified version as the new `SimpleMarkovChain` class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-07-08T22:04:23.462556Z",
          "start_time": "2019-07-08T22:04:23.453101Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9l-gJ_22WLVJ",
        "outputId": "91450b88-353f-4d5a-e4fb-10d1f5a883f8",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ATCGTCGACG\n"
          ]
        }
      ],
      "source": [
        "class SimpleMarkovChain:\n",
        "    ''' Generates sequences using a simple Markov Chain model '''\n",
        "    def __init__(self, s, k):\n",
        "        self.s = s\n",
        "        self.k = k\n",
        "        self.kth = better_context_probabilities(s, k)\n",
        "        self.zeroth = better_context_probabilities(s, 0)['']\n",
        "\n",
        "    def generate(self, n, seed=0):\n",
        "        ''' Generates a sequence of length n based on the Markov model '''\n",
        "        if n == 0:\n",
        "            return ''\n",
        "        if seed is not None:\n",
        "            np.random.seed(seed)\n",
        "\n",
        "        nucleotides = list('ACGT')\n",
        "        p_zeroth = list(self.zeroth.values())\n",
        "        start = np.random.choice(nucleotides, p=p_zeroth)\n",
        "        sequence = [start]\n",
        "        while n > len(sequence):\n",
        "            step = ''.join(sequence[-self.k:])\n",
        "            if step in self.kth:\n",
        "                next_nucleotide = np.random.choice(nucleotides, p=list(self.kth[step].values()))\n",
        "            else:\n",
        "                next_nucleotide = np.random.choice(nucleotides, p=p_zeroth)\n",
        "            sequence.append(next_nucleotide)\n",
        "\n",
        "        return ''.join(sequence)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    k = 2\n",
        "    s = 'ATGATATCATCGACGATGTAG'\n",
        "    n = 10\n",
        "    seed = 7\n",
        "    mc = SimpleMarkovChain(s, k)\n",
        "    print(mc.generate(n, seed))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yukAALSWLVK"
      },
      "source": [
        "### Idea of solution\n",
        "\n",
        "This method generates a sequence of length **n** using a simple `Markov Chain` based on enhanced context probability distributions. It is important to note that the body of the `while` loop now operates on lists and indices rather than directly on dictionary key values, which improves efficiency in the sequence generation process."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGdTnf56WLVK"
      },
      "source": [
        "### Discussion\n",
        "\n",
        "The function works as expected, providing similarly distributed sequences. The generative potential of `Markov Chains` can now be explored with more complex data and probability distributions, as we will demonstrate next."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGncofStWLVK"
      },
      "source": [
        "## $k$-mer index\n",
        "\n",
        "Our $k$-th order Markov chain can now be modified to a handy index structure called $k$-mer index. This index structure associates to each $k$-mer its list of occurrence positions in DNA sequence $T$.  Given a query $k$-mer $W$, one can thus easily list all positions $i$ with  $T[i..k-1]=W$.\n",
        "\n",
        "18. Implement function ```kmer_index``` inspired by your earlier code for the $k$-th order Markov chain. Test your program with `ATGATATCATCGACGATGTAG` and $k=2$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-07-08T22:04:23.504405Z",
          "start_time": "2019-07-08T22:04:23.494537Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwIbNduWWLVL",
        "outputId": "aed57531-5dad-4581-cc86-531ff1a3b5d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using string:\n",
            "ATGATATCATCGACGATGTAG\n",
            "012345678901234567890\n",
            "\n",
            "2-mer index is:\n",
            "{'AA': [], 'AC': [12], 'AG': [19], 'AT': [0, 3, 5, 8, 15], 'CA': [7], 'CC': [], 'CG': [10, 13], 'CT': [], 'GA': [2, 11, 14], 'GC': [], 'GG': [], 'GT': [17], 'TA': [4, 18], 'TC': [6, 9], 'TG': [1, 16], 'TT': []}\n"
          ]
        }
      ],
      "source": [
        "def kmer_index(s, k):\n",
        "    '''\n",
        "    Returns the starting indices of all k-mers in the sequence.\n",
        "    2-mer index is:\n",
        "    {'AA': [], 'AC': [12], 'AG': [19], 'AT': [0, 3, 5, 8, 15], 'CA': [7], ... }\n",
        "    '''\n",
        "    kth = better_context_probabilities(s, k)\n",
        "    k_indices = {}\n",
        "    for kmer in kth.keys():\n",
        "        start = 0\n",
        "        indices = []\n",
        "        while True:\n",
        "            start = s.find(kmer, start)\n",
        "            if start == -1:\n",
        "                break\n",
        "            indices.append(start)\n",
        "            start += 1\n",
        "        k_indices[kmer] = indices\n",
        "\n",
        "    return k_indices\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    k=2\n",
        "    s = 'ATGATATCATCGACGATGTAG'\n",
        "    print('Using string:')\n",
        "    print(s)\n",
        "    print(''.join([str(i%10) for i in range(len(s))]))\n",
        "    print(f'\\n{k}-mer index is:')\n",
        "    d = kmer_index(s, k)\n",
        "    print(dict(d))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "licO3AQPWLVM"
      },
      "source": [
        "### Idea of solution\n",
        "\n",
        "The `kmer_index()` function returns the start indices of each k-mer found in the given sequence. This function is useful for identifying the positions of specific k-mers within a larger sequence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYYr9-dxWLVM"
      },
      "source": [
        "### Discussion\n",
        "\n",
        "The output works as expected. Although the `kmer_index()` function will not be used further in this notebook, it still provides valuable insights about k-mer frequencies and positions. Possible uses can be the identification of motifs as well as the tracking and comparison of sequence elements across different datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNyJVIQjWLVM"
      },
      "source": [
        "## Comparison of probability distributions\n",
        "\n",
        "Now that we know how to learn probability distributions from data, we might want to compare two such distributions, for example, to test if our programs work as intended.\n",
        "\n",
        "Let $P=\\{p_1,p_2,\\ldots, p_n\\}$ and $Q=\\{q_1,q_2,\\ldots, q_n\\}$ be two probability distributions for the same set of $n$ events. This means $\\sum_{i=1}^n p_i=\\sum_{i=1}^n q_i=1$, $0\\leq p_j \\leq 1$, and $0\\leq q_j \\leq 1$ for each event $j$.\n",
        "\n",
        "*Kullback-Leibler divergence* is a measure $d()$ for the *relative entropy* of $P$ with respect to $Q$ defined as\n",
        "$d(P||Q)=\\sum_{i=1}^n p_i \\log\\frac{p_i}{q_i}$.\n",
        "\n",
        "\n",
        "This measure is always non-negative, and 0 only when $P=Q$. It can be interpreted as the gain of knowing $Q$ to encode $P$. Note that this measure is not symmetric.\n",
        "\n",
        "19. Write function ```kullback_leibler``` to compute $d(P||Q)$. Test your solution by generating a random RNA sequence\n",
        "  encoding the input protein sequence according to the input codon adaptation probabilities.\n",
        "  Then you should learn the codon adaptation probabilities from the RNA sequence you generated.\n",
        "  Then try the same with uniformly random RNA sequences (which don't have to encode any\n",
        "  specific protein sequence). Compute the relative entropies between the\n",
        "  three distribution (original, predicted, uniform) and you should observe a clear difference.\n",
        "  Because $d(P||Q)$ is not symmetric, you can either print both $d(P||Q)$ and $d(Q||P)$,\n",
        "  or their average.\n",
        "  \n",
        "  This problem may be fairly tricky. Only the `kullback_leibler` function is automatically tested. The codon probabilities is probably a useful helper function. The main guarded section can be completed by filling out the `pass` sections using tooling from previous parts and fixing the *placeholder* lines."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-07-08T22:04:23.557340Z",
          "start_time": "2019-07-08T22:04:23.539188Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3-bfzoXWLVN",
        "outputId": "dc65206f-3bc0-4f73-d5ee-942ea9d21d5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RNA to Protein succesful: True\n",
            "d(original || predicted) = 0.18330779879626566\n",
            "d(predicted || original) = 0.26109801878489997\n",
            "average = 0.2222029087905828\n",
            "\n",
            "d(original || uniform) = 0.2076934287813098\n",
            "d(uniform || original) = 0.2760279728471799\n",
            "average = 0.24186070081424485\n",
            "\n",
            "d(predicted || uniform) = 0.2463070478166842\n",
            "d(uniform || predicted) = 0.27493106443980964\n",
            "average = 0.26061905612824693\n"
          ]
        }
      ],
      "source": [
        "def codon_prob_from_sequence(rna):\n",
        "    '''\n",
        "    Given an RNA sequence, simply calculates the proability of\n",
        "    all 3-mers empirically based on the sequence\n",
        "    '''\n",
        "    k = 3\n",
        "    codon_dict = get_dict()\n",
        "    codon_counts = defaultdict(int) \n",
        "    probability_dict = {}\n",
        "\n",
        "    for i in range(0, len(rna) - k, k): # Collect context data\n",
        "        kmer = rna[i:i + k]\n",
        "        codon_counts[kmer] += 1\n",
        "\n",
        "    for codon in codon_dict.keys():\n",
        "        count = codon_counts.get(codon, 0)\n",
        "        probability_dict[codon] = (count + 1)/ (len(rna)/3 + 64) #Add pseudo counts\n",
        "\n",
        "    return probability_dict\n",
        "\n",
        "def codon_prob_from_table():\n",
        "    '''\n",
        "    Calculate probabilities for all codons based codon usage table\n",
        "    '''\n",
        "    html_content = get_table()\n",
        "    pre_content = re.search(r'<pre>(.*?)</pre>', html_content, re.DOTALL)  # Find all codon lines in the <pre> tag\n",
        "    if pre_content:\n",
        "        pre_data = pre_content.group(1)\n",
        "        # Initialize dictionaries to hold counts and probabilities\n",
        "        codon_counts = {}\n",
        "        total_count = 0\n",
        "        probability_dict = {}\n",
        "        # Find all matches for codons, amino acids, and counts\n",
        "        pattern = r'([AUGC]{3})\\s+([A-Z\\*])\\s+.*?\\s*\\(\\s*(\\d+)\\s*\\)'\n",
        "        matches = re.findall(pattern, pre_data)\n",
        "\n",
        "        # Calculate the counts\n",
        "        for codon, amino_acid, count in matches:  \n",
        "            codon_counts[codon] = int(count)\n",
        "            total_count += int(count)\n",
        "\n",
        "        # Calculate probabilities\n",
        "        for codon, count in codon_counts.items():\n",
        "            probability_dict[codon] = (count + 1 ) / (total_count + 64) #Add pseudo counts\n",
        "\n",
        "        return probability_dict\n",
        "\n",
        "def kullback_leibler(p, q):\n",
        "    '''\n",
        "    Computes Kullback-Leibler divergence between two distributions.\n",
        "    Both p and q must be dictionaries from events to probabilities.\n",
        "    The divergence is defined only when q[event] == 0 implies p[event] == 0.\n",
        "    '''\n",
        "    kl_divergence = 0\n",
        "    epsilon = 1e-6\n",
        "    for codon in p.keys():\n",
        "        kl_divergence += p[codon] * np.log2((p[codon] + epsilon) / (q[codon] + epsilon))\n",
        "    return kl_divergence\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    aas = list('*ACDEFGHIKLMNPQRSTVWY') # List of amino acids\n",
        "    n = 10000\n",
        "    # generate a random protein and some associated rna\n",
        "    protein = \"\".join(choice(aas, n))\n",
        "    rna = ProteinToRandomRNA().convert(protein)\n",
        "    # Maybe check that converting back to protein results in the same sequence\n",
        "    print('RNA to Protein succesful:', rna_to_prot(rna) == protein)\n",
        "    # Calculate codon probabilities of the rna sequence  \n",
        "    cp_predicted = codon_prob_from_sequence(rna)\n",
        "    # Calculate codon probabilities based on the codon usage table\n",
        "    cp_orig = codon_prob_from_table() \n",
        "    # Create a completely random RNA sequence and get the codon probabilities\n",
        "    # codons = [''.join(codon) for codon in product('ACGU', repeat = 3)]\n",
        "    # random_rna = ''.join(np.random.choice(codons, n))\n",
        "    random_rna = ''.join(np.random.choice(list('ACGU'), 3*n))\n",
        "    cp_uniform = codon_prob_from_sequence(random_rna)\n",
        "\n",
        "    print('d(original || predicted) =', kullback_leibler(cp_orig, cp_predicted))\n",
        "    print('d(predicted || original) =', kullback_leibler(cp_predicted, cp_orig))\n",
        "    print('average =', (kullback_leibler(cp_orig, cp_predicted) + kullback_leibler(cp_predicted, cp_orig))/2)\n",
        "    print()\n",
        "    print('d(original || uniform) =', kullback_leibler(cp_orig, cp_uniform))\n",
        "    print('d(uniform || original) =', kullback_leibler(cp_uniform, cp_orig))\n",
        "    print('average =', (kullback_leibler(cp_orig, cp_uniform) + kullback_leibler(cp_uniform, cp_orig))/2)\n",
        "    print()\n",
        "    print('d(predicted || uniform) =', kullback_leibler(cp_predicted, cp_uniform))\n",
        "    print('d(uniform || predicted) =', kullback_leibler(cp_uniform, cp_predicted))\n",
        "    print('average =', (kullback_leibler(cp_predicted, cp_uniform) + kullback_leibler(cp_uniform, cp_predicted))/2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tGrKIk4WLVN"
      },
      "source": [
        "### Idea of solution\n",
        "\n",
        "The `codon_prob_from_sequence()` function calculates the empirical probabilities of each 3-mer found in an RNA sequence, essentially recycling previous functionalities. Besides, the `codon_prob_from_table()` function calculates the probabilities for all codons based on the codon usage table. This time, the probability of each codon is calculated by dividing the number of that codon by the total codon number. This function differs from previously-defined 'def get_probability_dict)' calculate probabilities for all codons with respect to their amino acid.\n",
        "\n",
        "Subsequently, the `kullback_leibler()` function computes the Kullback-Leibler divergence between two probability distributions to quantify the difference between them. This is a straightforward implementation suitable for this notebook. The addition of `epsilon` makes the `p[codon]` and `q[codon]` have a non-zero value. This ensures the integrity of the divergence calculation without changing the final result much."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TVwtblpWLVN"
      },
      "source": [
        "### Discussion\n",
        "\n",
        "The Kullback-Leibler (KL) divergence values show that the predicted distribution closely approximates the original distribution. For example, $D_{\\text{KL}}(\\text{original} \\| \\text{predicted}) = 0.1833$ and $D_{\\text{KL}}(\\text{predicted} \\| \\text{original}) = 0.2620$, with an average of $0.2222$. These results indicate that the model effectively captures the characteristics of the data, with a small divergence between the predicted and original distributions.\n",
        "\n",
        "Both the original and predicted distributions do not differ significantly from the uniform distribution. For instance, $D_{\\text{KL}}(\\text{original} \\| \\text{uniform}) = 0.2077$ and $D_{\\text{KL}}(\\text{uniform} \\| \\text{original}) = 0.2760$, with an average divergence of $0.2419$. This suggests that the original distribution is relatively close to a uniform spread.\n",
        "\n",
        "Similarly, the predicted distribution aligns well with the uniform distribution, as evidenced by $D_{\\text{KL}}(\\text{predicted} \\| \\text{uniform}) = 0.2463$ and $D_{\\text{KL}}(\\text{uniform} \\| \\text{predicted}) = 0.2749$, yielding an average of $0.2606$. These values reinforce the observation that the predicted distribution, like the original, shows minimal divergence from uniformity.\n",
        "\n",
        "The asymmetry in KL divergence is apparent, with divergence values differing depending on the order of comparison. Overall, the results highlight the predictive model's capability to approximate the original distribution while showing that both the original and predicted distributions are relatively close to uniform distribution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8dsoFEIWLVO"
      },
      "source": [
        "## Stationary and equilibrium distributions (extra)\n",
        "\n",
        "Let us consider a Markov chain of order one on the set of nucleotides.\n",
        "Its transition probabilities can be expressed as a $4 \\times 4$ matrix\n",
        "$P=(p_{ij})$, where the element $p_{ij}$ gives the probability of the $j$th nucleotide\n",
        "on the condition the previous nucleotide was the $i$th. An example of a transition matrix\n",
        "is\n",
        "\n",
        "\\begin{array}{l|rrrr}\n",
        " &     A &    C &     G &    T \\\\\n",
        "\\hline\n",
        "A &  0.30 &  0.0 &  0.70 &  0.0 \\\\\n",
        "C &  0.00 &  0.4 &  0.00 &  0.6 \\\\\n",
        "G &  0.35 &  0.0 &  0.65 &  0.0 \\\\\n",
        "T &  0.00 &  0.2 &  0.00 &  0.8 \\\\\n",
        "\\end{array}.\n",
        "\n",
        "A distribution $\\pi=(\\pi_1,\\pi_2,\\pi_3,\\pi_4)$ is called *stationary*, if\n",
        "$\\pi = \\pi P$ (the product here is matrix product).\n",
        "\n",
        "20. Write function ```get_stationary_distributions``` that gets a transition matrix as parameter,\n",
        "  and returns the list of stationary distributions. You can do this with NumPy by\n",
        "  first taking transposition of both sides of the above equation to get equation\n",
        "  $\\pi^T = P^T \\pi^T$. Using numpy.linalg.eig take all eigenvectors related to\n",
        "  eigenvalue 1.0. By normalizing these vectors to sum up to one get the stationary distributions\n",
        "  of the original transition matrix. In the ```main``` function print the stationary distributions\n",
        "  of the above transition matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-07-08T22:04:23.591644Z",
          "start_time": "2019-07-08T22:04:23.580588Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7K_nnlL0WLVO",
        "outputId": "a6fc9878-0b88-4c23-a0e4-0a0520ccee69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+0.333, +0.000, +0.667, +0.000\n",
            "-0.000, +0.250, -0.000, +0.750\n"
          ]
        }
      ],
      "source": [
        "def get_stationary_distributions(transition):\n",
        "    '''\n",
        "    For a transition matrix of a degree one Markov chain,\n",
        "    it returns a list of stationary distributions.\n",
        "    '''\n",
        "    eigenval, eigenvec = np.linalg.eig(transition.T)\n",
        "    eigen_one = np.isclose(eigenval, 1, atol=1e-6)\n",
        "    # If no eigenvalue 1, return empty array\n",
        "    if not np.any(eigen_one):\n",
        "        return []\n",
        "    # Select eigenvectors for eigenvalue 1\n",
        "    selected = eigenvec[:, eigen_one]\n",
        "    # Normalize probabilities\n",
        "    stationary_distributions = selected / np.sum(selected, axis=0)\n",
        "    \n",
        "    return stationary_distributions.T\n",
        "    \n",
        "if __name__ == \"__main__\":\n",
        "    transition = np.array([[0.3, 0, 0.7, 0],\n",
        "                         [0, 0.4, 0, 0.6],\n",
        "                         [0.35, 0, 0.65, 0],\n",
        "                         [0, 0.2, 0, 0.8]])\n",
        "    for p in get_stationary_distributions(transition):\n",
        "        print(', '.join(f'{pv:+.3f}' for pv in p))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XS_oWHyWLVP"
      },
      "source": [
        "### Idea of solution\n",
        "\n",
        "The `get_stationary_distributions()` function derives the stationary distributions of a Markov chain represented by a transition matrix. It utilizes linear algebra concepts, specifically eigenvalues and eigenvectors (through NumPy `linalg.eig()`), to manipulate the transition matrix and obtain its stationary distributions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sze5-tsYWLVP"
      },
      "source": [
        "### Discussion\n",
        "\n",
        "Eigenvectors and eigenvalues provide a powerful framework for understanding the behavior of a matrix transformation. Eigenvectors define invariant directions in the data space, and eigenvalues quantify the scaling effect along those directions, enabling an alternative coordinate system that preserves the system's internal coherence. The eigenvector associated with an eigenvalue of 1 is particularly significant, as it represents a stationary state; when the system starts in this distribution, it remains unchanged under repeated applications of the transformation. This concept is essential in various fields, such as Markov chains and dynamical systems, where it explains equilibrium states or steady-state behavior.\n",
        "\n",
        "The resulting distributions indicate the long-term probabilities of being in each state of the Markov chain. For example, in the **first distribution**, the corresponding eigenvectors indicate that there is a $33.3$% chance of being in state 1 (*A*) and a $66.7$% chance of being in state 3 (*G*) in the long run. In the **second distribution**,  the corresponding eigenvectors indicate that there is a $25$% chance of being in state 2 (*C*) and a $75$% chance of being in state 4 (*T*) in the long run. This is coherent with the provided transition matrix, which is heavily skewed to either one cluster of nucleotides or the other (*A* and *G*, or *C* and *T*)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-snrO4PWLVP"
      },
      "source": [
        "21. Implement the `kl_divergence` function below so that the main guarded code runs properly. Using your modified Markov chain generator generate a nucleotide sequence $s$ of length $10\\;000$. Choose prefixes of $s$ of lengths $1, 10, 100, 1000$, and $10\\;000$. For each of these prefixes find out their nucleotide distribution (of order 0) using your earlier tool. Use 1 as the pseudo count. Then, for each prefix, compute the KL divergence between the initial distribution and the normalized nucleotide distribution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-07-08T22:04:23.635060Z",
          "start_time": "2019-07-08T22:04:23.618890Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6J-CAOHWLVP",
        "outputId": "2c11d202-9f42-4e55-eb81-3773937751be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transition probabilities are:\n",
            "[[0.3  0.   0.7  0.  ]\n",
            " [0.   0.4  0.   0.6 ]\n",
            " [0.35 0.   0.65 0.  ]\n",
            " [0.   0.2  0.   0.8 ]]\n",
            "Stationary distributions:\n",
            "[[ 0.33333333  0.          0.66666667  0.        ]\n",
            " [-0.          0.25       -0.          0.75      ]]\n",
            "Using [-0.00, 0.25, -0.00, 0.75] as initial distribution\n",
            "\n",
            "KL divergence of stationary distribution prefix of length     1 is 0.76064835\n",
            "KL divergence of stationary distribution prefix of length    10 is 0.24607653\n",
            "KL divergence of stationary distribution prefix of length   100 is 0.03043537\n",
            "KL divergence of stationary distribution prefix of length  1000 is 0.00309521\n",
            "KL divergence of stationary distribution prefix of length 10000 is 0.00045159\n"
          ]
        }
      ],
      "source": [
        "class ModdedMarkovChain:\n",
        "    ''' Generates sequences using a modified Markov Chain model '''\n",
        "    def __init__(self, initial, transition):\n",
        "        self.initial = initial\n",
        "        self.transition = transition\n",
        "\n",
        "    def generate(self, n, seed=None):\n",
        "        ''' Generates a sequence of length n using the modified Markov model '''\n",
        "        if n == 0:\n",
        "            return ''\n",
        "        if seed is not None:\n",
        "            np.random.seed(seed)\n",
        "\n",
        "        nucleotide_map = dict(zip(list('ACGT'), range(4)))\n",
        "        start = np.random.choice(list('ACGT'), p=self.initial)\n",
        "        sequence = [start]\n",
        "        while n > len(sequence):\n",
        "            next_nucleotide = np.random.choice(list('ACGT'), p=self.transition[nucleotide_map[sequence[-1]], :])\n",
        "            sequence.append(next_nucleotide)\n",
        "\n",
        "        return ''.join(sequence)\n",
        "\n",
        "def nucleotide_distribution(prefix):\n",
        "    ''' Calculate the nucleotide distribution for a given prefix. '''\n",
        "    total = len(prefix) + 4 # Add 4 for pseudo-counts\n",
        "    \n",
        "    for nucleotide in 'ACGT':\n",
        "        distribution[nucleotide] = (prefix.count(nucleotide) + 1) / total # Add pseudo-counts\n",
        "    return distribution\n",
        "\n",
        "def kl_divergences(initial, transition):\n",
        "    '''\n",
        "    Calculates Kullback-Leibler divergences between empirical distributions\n",
        "    generated using a Markov model seeded with an initial distribution and a transition\n",
        "    matrix, and the initial distribution.\n",
        "    Sequences of length [1, 10, 100, 1000, 10000] are generated.\n",
        "    '''\n",
        "    n = 10000\n",
        "    seq = ModdedMarkovChain(initial, transition).generate(n)\n",
        "\n",
        "    # Create the initial distribution \n",
        "    p = {nucleotide: prob for nucleotide, prob in zip('ACGT', initial)}\n",
        "\n",
        "    results = []\n",
        "    for length in [1, 10, 100, 1000, 10000]:\n",
        "        prefix = seq[:length]\n",
        "        q = nucleotide_distribution(prefix)\n",
        "        kl_divergence = kullback_leibler(p, q)\n",
        "        results.append((length, kl_divergence))\n",
        "\n",
        "    return results\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    transition = np.array([[0.3, 0, 0.7, 0],\n",
        "                       [0, 0.4, 0, 0.6],\n",
        "                       [0.35, 0, 0.65, 0],\n",
        "                       [0, 0.2, 0, 0.8]])\n",
        "    print('Transition probabilities are:')\n",
        "    print(transition)\n",
        "    stationary_distributions = get_stationary_distributions(transition)\n",
        "    print('Stationary distributions:')\n",
        "    print(np.stack(stationary_distributions))\n",
        "    initial = stationary_distributions[1]\n",
        "    print('Using [{}] as initial distribution\\n'.format(', '.join(f'{v:.2f}' for v in initial)))\n",
        "    results = kl_divergences(initial, transition)\n",
        "    for prefix_length, divergence in results: # iterate on prefix lengths in order (1, 10, 100...)\n",
        "        print('KL divergence of stationary distribution prefix ' \\\n",
        "              'of length {:5d} is {:.8f}'.format(prefix_length, divergence))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJ-XeH3xWLVQ"
      },
      "source": [
        "### Idea of solution\n",
        "\n",
        "For this exercise, it was necessary to modify the previous `MarkovChain` class to generate a sequence using an initial distribution and transition matrix, rather than relying on zeroth and k-th order probabilities. The `nucleotide_distribution()` function calculates the distribution of nucleotides within a given sequence prefix for frequency analysis. Subsequently, the `kl_divergences()` function computes KL divergences between empirical distributions derived from sequences generated by a Markov model and an equilibrium distribution across various lengths."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzlC4pNVWLVQ"
      },
      "source": [
        "### Discussion\n",
        "\n",
        "The KL divergence results provide insight into how closely the initial distribution (*A*: 0, *C*: 0.25, *G*: 0, *T*: 0.75) approximates the stationary distribution over time. The decreasing KL divergence values indicate that as the length of the sequence increases, the initial distribution converges towards the stationary distribution. Specifically:\n",
        "\n",
        "* At a prefix length of 1, the KL divergence is $0.760$, suggesting a significant difference between the initial and stationary distributions.\n",
        "* By a prefix length of 10, the divergence decreases to $0.246$, indicating a closer alignment.\n",
        "* At lengths of 100, 1000, and 10,000, the KL divergence continues to decrease significantly, reaching values as low as $0.00045$, which implies that the initial distribution closely resembles the stationary distribution after many transitions.\n",
        "\n",
        "In summary, the KL divergence analysis shows that the Markov chain is likely to stabilize, with the initial distribution converging towards the stationary distribution as the number of transitions increases. This behavior highlights the system's tendency to reach a steady state, which is crucial for understanding its long-term dynamics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4wci5ZaWLVQ"
      },
      "source": [
        "22. Implement the following in the ```main``` function.\n",
        "Find the stationary distribution for the following transition matrix:  \n",
        "\n",
        "\\begin{array}{ l | r r r r}\n",
        " & A &     C &     G &     T \\\\\n",
        "\\hline\n",
        "A &  0.30 &  0.10 &  0.50 &  0.10 \\\\\n",
        "C &  0.20 &  0.30 &  0.15 &  0.35 \\\\\n",
        "G &  0.25 &  0.15 &  0.20 &  0.40 \\\\\n",
        "T &  0.35 &  0.20 &  0.40 &  0.05 \\\\\n",
        "\\end{array}\n",
        "\n",
        "Since there is only one stationary distribution, it is called the *equilibrium distribution*.\n",
        "Choose randomly two nucleotide distributions. You can take these from your sleeve or\n",
        "sample them from the Dirichlet distribution. Then for each of these distributions\n",
        "as the initial distribution of the Markov chain, repeat the above experiment.\n",
        "\n",
        "The `main` function should return tuples, where the first element is the (random) initial distribution and the second element contains the results as a list of tuples where the first element is the kl divergence and the second element the empirical nucleotide distribution, for the different prefix lengths.\n",
        "\n",
        "The state distribution should converge to the equilibrium distribution no matter how we\n",
        "start the Markov chain! That is the last line of the tables should have KL-divergence very close to $0$ and an empirical distribution very close to the equilibrium distribution.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-07-08T22:04:23.681300Z",
          "start_time": "2019-07-08T22:04:23.657345Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2EBwCyq1WLVQ",
        "outputId": "6ff934ba-dd2d-48f9-c7ee-a4e86ef22558"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transition probabilities are:\n",
            "[[0.3  0.1  0.5  0.1 ]\n",
            " [0.2  0.3  0.15 0.35]\n",
            " [0.25 0.15 0.2  0.4 ]\n",
            " [0.35 0.2  0.4  0.05]]\n",
            "Equilibrium distribution:\n",
            "[0.27803345 0.17353238 0.32035021 0.22808396]\n",
            "\n",
            "Using [0.39399635 0.48660671 0.01076917 0.10862777] as initial distribution:\n",
            "kl-divergence   empirical distribution\n",
            "0.18403   [0.2, 0.4, 0.2, 0.2]\n",
            "0.13014   [0.21428571428571427, 0.35714285714285715, 0.21428571428571427, 0.21428571428571427]\n",
            "0.01497   [0.22115384615384615, 0.18269230769230768, 0.3269230769230769, 0.2692307692307692]\n",
            "0.00181   [0.2559760956175299, 0.17828685258964144, 0.3296812749003984, 0.2360557768924303]\n",
            "0.00026   [0.27658936425429825, 0.16873250699720113, 0.328468612554978, 0.2262095161935226]\n",
            "\n",
            "Using [0.38030874 0.24251191 0.25314513 0.12403423] as initial distribution:\n",
            "kl-divergence   empirical distribution\n",
            "0.18403   [0.2, 0.4, 0.2, 0.2]\n",
            "0.13014   [0.21428571428571427, 0.35714285714285715, 0.21428571428571427, 0.21428571428571427]\n",
            "0.01497   [0.22115384615384615, 0.18269230769230768, 0.3269230769230769, 0.2692307692307692]\n",
            "0.00181   [0.2559760956175299, 0.17828685258964144, 0.3296812749003984, 0.2360557768924303]\n",
            "0.00026   [0.27658936425429825, 0.16873250699720113, 0.328468612554978, 0.2262095161935226]\n",
            "0.12948   [0.2, 0.2, 0.2, 0.4]\n",
            "0.09732   [0.2857142857142857, 0.07142857142857142, 0.42857142857142855, 0.21428571428571427]\n",
            "0.01737   [0.3269230769230769, 0.18269230769230768, 0.3173076923076923, 0.17307692307692307]\n",
            "0.00233   [0.28784860557768926, 0.18426294820717132, 0.32171314741035856, 0.2061752988047809]\n",
            "0.00034   [0.2854858056777289, 0.1688324670131947, 0.32287085165933627, 0.22281087564974011]\n"
          ]
        }
      ],
      "source": [
        "def generate_random_alpha(num_params, low=1, high=20):\n",
        "    ''' Generate a random set of alpha parameters for the Dirichlet distribution '''\n",
        "    return np.random.randint(low, high, size=num_params)\n",
        "\n",
        "def main(transition, equilibrium_distribution):\n",
        "    ''' Main function to generate distributions and results as an iterable '''\n",
        "    results = []\n",
        "    # Ensure reproductibility for KL divergence\n",
        "    np.random.seed(0)\n",
        "    # Generate two different initial distributions\n",
        "    for _ in range(2):\n",
        "        alphas = generate_random_alpha(4, low=1, high=20)\n",
        "        initial = np.random.dirichlet(alphas, size=1)[0]\n",
        "        # Number of samples\n",
        "        n = 10000\n",
        "        seq = ModdedMarkovChain(initial, transition).generate(n)\n",
        "        # Create the initial distribution\n",
        "        p = {nucleotide: prob for nucleotide, prob in zip('ACGT', equilibrium_distribution)}\n",
        "\n",
        "        for length in [1, 10, 100, 1000, 10000]:\n",
        "            prefix = seq[:length]\n",
        "            q = nucleotide_distribution(prefix)\n",
        "            kl_divergence = kullback_leibler(p, q)  # Compare with equilibrium distribution\n",
        "            results.append((kl_divergence, [probability for probability in q.values()]))\n",
        "\n",
        "        # Yield the initial distribution and results as a single iterable\n",
        "        yield initial, results\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    transition = np.array([[0.3, 0.1, 0.5, 0.1],\n",
        "                           [0.2, 0.3, 0.15, 0.35],\n",
        "                           [0.25, 0.15, 0.2, 0.4],\n",
        "                           [0.35, 0.2, 0.4, 0.05]])\n",
        "    \n",
        "    print('Transition probabilities are:', transition, sep='\\n')\n",
        "    stationary_distributions = get_stationary_distributions(transition)\n",
        "    # Uncomment the below line to check that there actually is only one stationary distribution\n",
        "    # assert len(stationary_distributions) == 1\n",
        "    equilibrium_distribution = stationary_distributions[0]\n",
        "    print('Equilibrium distribution:')\n",
        "    print(equilibrium_distribution)\n",
        "    for initial_distribution, results in main(transition, equilibrium_distribution):\n",
        "        print('\\nUsing {} as initial distribution:'.format(initial_distribution))\n",
        "        print('kl-divergence   empirical distribution')\n",
        "        print('\\n'.join('{:.5f}   {}'.format(di, kl) for di, kl in results))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVtuj94FWLVR"
      },
      "source": [
        "### Idea of solution\n",
        "\n",
        "The `generate_random_alpha()` function generates a uniformly random set of integer alpha parameters suitable for a Dirichlet distribution within specified bounds. The `main()` function serves as the control loop for generating and iteratively sampling sequences from a Markov chain, while calculating Kullback-Leibler divergences to assess the similarities between generated and equilibrium distributions. A random seed is set at the beginning to ensure the reproducibility of the KL results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxqJX4N6WLVR"
      },
      "source": [
        "### Discussion\n",
        "\n",
        "The transition matrix describes the probabilities of transitioning between the four nucleotide states: **A**, **C**, **G**, and **T**. Each row of the matrix sums to 1. The equilibrium distribution, which is the stationary distribution for this Markov chain, is calculated to be approximately:\n",
        "\n",
        "- **A**: $27.8$%\n",
        "- **C**: $17.4$%\n",
        "- **G**: $32.0$%\n",
        "- **T**: $22.8$%\n",
        "\n",
        "This distribution indicates the long-term probabilities of being in each state, regardless of the initial distribution. To test the convergence of the Markov chain to this equilibrium distribution, two random initial distributions were generated using the Dirichlet distribution. This distribution is flexible enough to model probabilities that sum to one (such as proportions of nucleotide frequencies). By generating initial conditions with this distribution and measuring KL divergence at various lengths, we can gain valuable insights into the behavior of our Markov chain models.\n",
        "\n",
        "The results show how the state distribution evolves over time with a sequence of 10,000 samples for the **Initial Distribution 1**. The KL divergence begins at $0.184$, straying moderately from the equilibrium distribution. As the sequence length increases, the KL divergence decreases, reaching values as low as $0.00026$, demonstrating that the empirical distribution converges closely to the equilibrium distribution. An essentially identical process was observed for the **Initial Distribution 2**, with the final KL divergence reaching $0.00034$, and the empirical distribution also approximating the equilibrium distribution.\n",
        "\n",
        "| Initial Distribution | Base State | Initial Probability | Final Probability | KL Divergence       |\n",
        "|---------------------|------------|---------------------|-------------------|----------------------|\n",
        "| 1                   | A          | 39.4%               | 27.7%             | 0.184                |\n",
        "|                     | C          | 48.7%               | 16.9%             |                      |\n",
        "|                     | G          |  1.1%               | 32.8%             |                      |\n",
        "|                     | T          | 10.9%               | 22.6%             |                      |\n",
        "|                     |            |                     |                   |                      |\n",
        "| 2                   | A          | 38.0%               | 28.5%             | 0.1840               |\n",
        "|                     | C          | 24.3%               | 16.9%             |                      |\n",
        "|                     | G          | 25.3%               | 32.3%             |                      |\n",
        "|                     | T          | 12.4%               | 22.2%             |                      |\n",
        "\n",
        "\n",
        "The results confirm that regardless of the initial distribution chosen, the Markov chain converges to the equilibrium distribution. The KL divergence values consistently decrease, indicating that the empirical distributions become increasingly similar to the equilibrium distribution as the number of samples increases. This behavior illustrates the fundamental property of Markov chains: they tend to reach a steady state over time, which is crucial for understanding their long-term dynamics."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "tf",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "position": {
        "height": "598.85px",
        "left": "1223px",
        "right": "20px",
        "top": "121px",
        "width": "353px"
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
